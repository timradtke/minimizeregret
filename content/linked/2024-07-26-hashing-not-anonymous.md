---
title: "No, Hashing Still Doesn't Make Your Data Anonymous"
linktitle: https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2024/07/no-hashing-still-doesnt-make-your-data-anonymous
author: Tim Radtke
date: '2024-07-26'
slug: hashing-not-anonymous
categories:
tags:
---

Just the Federal Trade Commission (FTC) reminding all of us that you can't anonymize private data by hashing unique identifiers.

And the stories the FTC has to tell:

> In 2022 the FTC brought a case against an online counseling service BetterHelp, alleging they had shared consumers’ sensitive health data—including hashed email addresses—with Facebook. The complaint laid out that BetterHelp knew that Facebook would “undo the hashing and reveal the email addresses of those Visitors and Users.” Though BetterHelp sent hashes to Facebook, rather than email addresses, the outcome was the same: Facebook allegedly learned who was seeking counselling for mental health and used that sensitive information to target ads to them.

What will be the equivalent to hashing when it comes to regulation of AI? When reviewing a company's practices, hashing is straightforward to find and offers a black-and-white case. But when reviewing "[an appropriate level of accuracy](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)" of a system or the "[appropriate measures to detect, prevent and mitigate possible biases](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=OJ:L_202401689)", what will clearly be not good enough?