---
title: SAP Design Guidelines for Intelligent Systems
linktitle: https://experience.sap.com/fiori-design-web/designing-intelligent-systems/
author: Tim Radtke
date: '2023-01-08'
slug: sap-design-guidelines
categories:
tags:
---

From SAP’s [Design Guidelines for Intelligent Systems](https://experience.sap.com/fiori-design-web/recommendations/):

> **High–stakes decisions** are more common in a professional software environment than in everyday consumer apps, where the consequences of an action are usually easy to anticipate and revert.
While the implications of recommending unsuitable educational content to an employee are likely to be minimal, recommendations around critical business decisions can potentially cause irreversible damage (for example, recommending an unreliable supplier or business partner, leading to the failure or premature termination of a project or contract).
It’s therefore vital to enable users to take an **informed decision**.

While sometimes overlooked, this guide presents software in internal business processes as rich opportunity to augment human capabilities, deserving just as much love and attention as "everyday consumer apps".

The chapters on intelligent systems are not too tuned to SAP systems, but they do have the specific context of business applications in mind which differentiates them from other (great!) [guides on user interfaces for machine learning systems](https://pair.withgoogle.com/guidebook/).

Based on that context, the guide dives deep on [Ranking](https://experience.sap.com/fiori-design-web/ranking/), [Recommendations](https://experience.sap.com/fiori-design-web/recommendations/), and [Matching](https://experience.sap.com/fiori-design-web/matching/), proving that it's based on a much more hands-on view than any text discussing Supervised, Unsupervised, and Reinforcement Learning.

When aiming to build systems that "augment human capabilities", the importance of "gain[ing] the user’s trust and foster[ing] successful adoption" can’t be overstated, making it worthwhile to deeply consider how we present the output of our systems.

Related: [Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI](https://arxiv.org/abs/2010.07487) by Alon Jacovi, Ana Marasović, Tim Miller, and Yoav Goldberg.